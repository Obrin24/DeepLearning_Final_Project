{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU for training.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU for training.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU available, using CPU for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and split into training, validation and testing datasets\n"
     ]
    }
   ],
   "source": [
    "%run \"../DL_notebooks/src/dataloading.ipynb\"\n",
    "%run \"../DL_notebooks/src/training.ipynb\"\n",
    "%run \"../DL_notebooks/src/evaluate.ipynb\"\n",
    "%run \"../DL_notebooks/src/visualizations.ipynb\"\n",
    "%run \"../DL_notebooks/model_architectures.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_current_model(json_file, new_model_name):\n",
    "    # Load the JSON data from the file\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Update the current-model value\n",
    "    data['current-model'] = new_model_name\n",
    "\n",
    "    # Save the updated JSON data back to the file\n",
    "    with open(json_file, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "json_file_path = '../DL_notebooks/configs/model_configs.json'\n",
    "new_model_name = 'CNN'\n",
    "update_current_model(json_file_path, new_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gabeb\\Documents\\GitHub\\DeepLearning_Final_Project\\ML_notebooks\\cross_validations.ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gabeb/Documents/GitHub/DeepLearning_Final_Project/ML_notebooks/cross_validations.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model_architectures \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gabeb/Documents/GitHub/DeepLearning_Final_Project/ML_notebooks/cross_validations.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m config \u001b[39min\u001b[39;00m model_configs:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gabeb/Documents/GitHub/DeepLearning_Final_Project/ML_notebooks/cross_validations.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     model_architecture \u001b[39m=\u001b[39m config[\u001b[39m'\u001b[39;49m\u001b[39mmodel-architecture\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gabeb/Documents/GitHub/DeepLearning_Final_Project/ML_notebooks/cross_validations.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     epochs \u001b[39m=\u001b[39m config[\u001b[39m'\u001b[39m\u001b[39mepoch-count\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gabeb/Documents/GitHub/DeepLearning_Final_Project/ML_notebooks/cross_validations.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     optimizer_lr \u001b[39m=\u001b[39m config[\u001b[39m'\u001b[39m\u001b[39moptimizer-lr\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "with open('../DL_notebooks/configs/model_configs.json', 'r') as model_config_file:\n",
    "    model_configs = json.load(model_config_file)\n",
    "\n",
    "models = []\n",
    "model_architectures = []\n",
    "for config in model_configs:\n",
    "    model_architecture = config['model-architecture']\n",
    "    epochs = config['epoch-count']\n",
    "    optimizer_lr = config['optimizer-lr']\n",
    "    model_architectures.append(model_architecture)\n",
    "\n",
    "    match model_architecture:\n",
    "        case 'CNN':\n",
    "            model = MRI_CNN(**config['cnn-model-hyperparameters'])\n",
    "            model = model.to(device)\n",
    "        case 'ResNet':\n",
    "            num_classes = config['resnet-model-hyperparameters']['num_classes']\n",
    "            layers = config['resnet-model-hyperparameters']['layers']\n",
    "            model = MRI_ResNet(BasicBlock, layers, num_classes)\n",
    "            model = model.to(device)\n",
    "        case 'ResNet2':\n",
    "            num_classes2 = config['resnet2-model-hyperparameters']['num_classes']\n",
    "            model = MRI_ResNet2(num_classes2)\n",
    "            model = model.to(device)\n",
    "            match config['optimizer']:\n",
    "                case 'adamW':\n",
    "                    optimizer = optim.AdamW(model.parameters(), lr=optimizer_lr)\n",
    "                case _:\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=optimizer_lr)\n",
    "        case 'AlexNet':\n",
    "            num_classes = config['alexnet-model-hyperparameters']['num_classes']\n",
    "            model = MRI_AlexNet(num_classes)\n",
    "            model = model.to(device)\n",
    "\n",
    "    match config['loss-function']:\n",
    "        case 'cross-entropy':\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        case _:\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if config['optimizer'] == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=optimizer_lr)\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=optimizer_lr)\n",
    "\n",
    "    \n",
    "    models.append((model, criterion, optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 3/20 [01:38<08:58, 31.66s/epoch]"
     ]
    }
   ],
   "source": [
    "num_splits = 5\n",
    "\n",
    "stratified_kf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "model_results = []\n",
    "for model, criterion, optimizer in models:\n",
    "    fold_results = []\n",
    "    train_loader_fold = train_loader\n",
    "    val_loader_fold = val_loader\n",
    "    val_accuracies = []\n",
    "    training_accuracies = []\n",
    "    count = 0\n",
    "    for train_index, val_index in stratified_kf.split(train_labels, train_labels):\n",
    "\n",
    "        for epoch in tqdm(range(epochs), desc=\"Training\", unit=\"epoch\"):\n",
    "            train_loss, train_accuracy, _, _ = train(model, train_loader=train_loader_fold, optimizer=optimizer, criterion=criterion, device=device)\n",
    "            training_accuracies.append(train_accuracy)\n",
    "            val_loss, val_accuracy, val_labels, val_preds = evaluate(model, val_loader_fold, criterion=criterion, device=device)\n",
    "            fold_results.append({\n",
    "                \"train_loss\": train_loss,\n",
    "                \"train_accuracy\": train_accuracy,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_accuracy\": val_accuracy,\n",
    "            })\n",
    "            val_accuracies.append(val_accuracy)\n",
    "        \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(training_accuracies, label=\"Training Accuracy\")\n",
    "    plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "    plt.title(f\"Training and Validation Accuracy Over Time for {model_architectures[count]}\")\n",
    "    plt.xlabel(\"Fold\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    avg_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
    "    model_results.append((model, avg_val_accuracy))\n",
    "    count = count + 1\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = []\n",
    "test_accuracies = []\n",
    "best_model = max(model_results, key=lambda x: x[1][\"val_accuracy\"])\n",
    "best_model, best_metrics = best_model\n",
    "\n",
    "\n",
    "print(f\"Average Validation Accuracy: {best_metrics['val_accuracy']:.4f}\")\n",
    "print(f\"Average Validation Loss: {best_metrics['val_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(epochs), desc=\"Testing\", unit=\"epoch\"):\n",
    "    start_time = time.time()\n",
    "    test_loss, test_accuracy, test_labels, test_preds = evaluate(model, test_loader, criterion=criterion, device=device)\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_time = end_time - start_time\n",
    "\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    tqdm.write(\n",
    "        f\"Testing Epoch [{epoch + 1}/{epochs}] \"\n",
    "        f\"Test Loss: {test_loss:.4f} \"\n",
    "        f\"Test Accuracy: {test_accuracy * 100:.2f}% \"\n",
    "        f\"Time per Epoch: {epoch_time:.2f} seconds\"\n",
    "    )\n",
    "\n",
    "avg_test_loss = sum(test_losses) / len(test_losses)\n",
    "avg_test_accuracy = sum(test_accuracies) / len(test_accuracies)\n",
    "print(f\"Average Test Loss: {avg_test_loss:.4f}\")\n",
    "print(f\"Average Test Accuracy: {avg_test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, accuracies in validation_accuracies.items():\n",
    "    plt.plot(range(epochs), accuracies, label=model_name)\n",
    "\n",
    "plt.title(\"Validation Accuracies Over Time\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
